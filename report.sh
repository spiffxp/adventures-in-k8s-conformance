#!/usr/bin/env bash
#
# This script assumes it's run in a directory with k8s test results that were
# generated by kubernetes CI, stored in GCS, accessible via websites such as
# testgrid.k8s.io, gubernator.k8s.io, gcsweb.k8s.io, etc.
#
# ./report.sh
# ./job-name/run-number/finished.json
# ./job-name/run-number/junit_01.xml
# ./job-name/run-number/kube-apiserver-audit.log
#
# This script comes from github.com/spiffxp/adventures-in-k8s-conformance
# which contains some directories that were prepopulated with the data used to
# generate charts for the talk.  The audit logs were not included due to their
# size, so instead the api coverage databases have been precomputed and
# gzipped. This script will decompress them when it finds them.


set -eu

# change this to your local copy of apisnoop
apisnoop_dir="${HOME}/w/cncf/apisnoop/dev/e2e-coverage-view"
output_csv=true
recompute_e2e_coverage_view_db=false

coverage_csv() {
  local db=$1
  local where_clause=$2
  local q=$(cat <<EOS
select covered, total, round(100.0*covered/total,2) as coverage
from (
  select count(*) as covered, total 
  from ( 
    select distinct e.url, e.method 
    from Endpoint e 
    join EndpointHit eh on eh.endpoint = e.id
    ${where_clause} 
    order by e.url, e.method 
  ) join (
    select count(*) as total
    from ( 
      select distinct e.url, e.method 
      from Endpoint e 
      ${where_clause}
    )
  ) 
);
EOS
  )
  echo $q | sqlite3 ${db} | sed -e 's/|/, /g'
}

testcase_count_by_endpoint_q=$( cat <<EOS
select count(*) as cases, method || " " || url as endpoint 
from (
  select distinct eh.user_agent, e.method, e.url 
  from Endpoint e 
  join EndpointHit eh on eh.endpoint = e.id 
  where eh.user_agent not like '%/v%'
) 
group by 
  method, url 
order by 
  cases
EOS
)

# output csv headers for these test results
if ${output_csv}; then
  printf "%-45s, %-5s, %-10s, %-20s, %-5s" job run run_at version tests
  echo ", cov, tot, pct, cov_s, tot_s, pct_s, cov_sc, tot_sc, pct_sc"
fi

for d in $(find . -type d -depth 2 -exec echo -n {} " " \; -exec jq -r .version {}/finished.json \; | sort -k 2 | cut -d\  -f1); do
  abs_d=$(realpath ${d})
  job=$(echo ${d} | cut -d/ -f2)
  run_num=$(echo ${d} | cut -d/ -f3)
  finished=${d}/finished.json
  junit=${d}/junit_01.xml
  audit_log=${abs_d}/kube-apiserver-audit.log
  e2e_coverage_sqlite_db=${abs_d}/e2e-coverage-view.database.sqlite

  if ! [[ -f ${finished} ]]; then
    echo "ERROR: missing finished: ${finished}"
    exit 1
  fi
  if ! [[ -f ${junit} ]]; then
    echo "ERROR: missing junit: ${junit}"
    exit 1
  fi

  # what version of kubernetes was tested, when was it tested
  version=$(<${finished} jq -r .version)
  version_without_sha=$(echo ${version} | cut -d+ -f1)
  run_at=$(<${finished} jq -r '.timestamp | todate' | cut -dT -f1)

  # list out test cases for manual diffing later, get count of them for csv
  testcases=${d}/testcases.txt
  grep testcase.*/testcase ${d}/junit_*.xml | sed -e 's/.* name="\([^"]*\)".*/\1/' | sort > ${testcases}
  num_tests=$(wc -l ${testcases} | awk '{ print $1}')

  # need a sha if version isn't a tag, to know which openapi spec to diff against
  apisnoop_version_param=${version}
  if [[ "${apisnoop_version_param}" =~ "+" ]]; then
    apisnoop_version_param=$(echo ${apisnoop_version_param} | cut -d+ -f2)
  fi
  
  # use apisnoop to get api coverage data for test results that have audit logs
  if [[ -f "${audit_log}" ]]; then
    if ${recompute_e2e_coverage_view_db} || ! [[ -f ${e2e_coverage_sqlite_db} ]]; then
        echo "Recomputing ${e2e_coverage_sqlite_db} for ${job} #${run_num}"
        pushd ${apisnoop_dir}
        rm database.sqlite
        python import.py "${audit_log}" "${apisnoop_version_param}"
        cp database.sqlite ${e2e_coverage_sqlite_db}
        popd
    fi
  fi
  # gunzip any precomputed api coverage data
  if [[ -f "${e2e_coverage_sqlite_db}.gz" ]]; then
    gunzip "${e2e_coverage_sqlite_db}.gz"
  fi

  # prevent stale output for results that don't have coverage data
  cov_tot_pct_all=""
  cov_tot_pct_stable=""
  cov_tot_pct_stablecore=""

  # if we have api coverage data, run some queries against it
  if [[ -f "${e2e_coverage_sqlite_db}" ]]; then
    cov_tot_pct_all=$(coverage_csv ${e2e_coverage_sqlite_db} "")
    cov_tot_pct_stable=$(coverage_csv ${e2e_coverage_sqlite_db} "where e.level = 'stable'")
    cov_tot_pct_stablecore=$(coverage_csv ${e2e_coverage_sqlite_db} "where e.level = 'stable' and e.category = 'core'")

    query_to_file_and_linecount() {
      local file=$1
      local q=$2
      echo $q | sqlite3 ${e2e_coverage_sqlite_db} | tr '|' ',' > ${file}
      wc -l ${file} | awk '{print $1}'
    }

    q="select distinct e.url,e.method from Endpoint e order by e.url, e.method;"
    total_all_endpoints=$(query_to_file_and_linecount ${d}/total_all_endpoint_list.csv "${q}")

    q="select distinct e.url,e.method from Endpoint e join EndpointHit eh on eh.endpoint = e.id order by e.url, e.method;"
    covered_all_endpoints=$(query_to_file_and_linecount ${d}/covered_all_endpoint_list.csv "${q}")

    q="select distinct e.url,e.method from Endpoint e where e.level = 'stable' order by e.url, e.method;"
    total_stable_endpoints=$(query_to_file_and_linecount ${d}/total_stable_endpoint_list.csv "${q}")

    q="select distinct e.url,e.method from Endpoint e join EndpointHit eh on eh.endpoint = e.id where e.level = 'stable' order by e.url, e.method;"
    covered_stable_endpoints=$(query_to_file_and_linecount ${d}/covered_stable_endpoint_list.csv "${q}")

    q="select distinct e.url,e.method from endpoint e where e.level = 'stable' and e.category = 'core' order by e.url, e.method;"
    total_stablecore_endpoints=$(query_to_file_and_linecount ${d}/total_stablecore_endpoint_list.csv "${q}")

    q="select distinct e.url,e.method from Endpoint e join EndpointHit eh on eh.endpoint = e.id where e.level = 'stable' and e.category = 'core' order by e.url, e.method;"
    covered_stablecore_endpoints=$(query_to_file_and_linecount ${d}/covered_stablecore_endpoint_list.csv "${q}")

    ignore_count=$(query_to_file_and_linecount ${d}/testcase_count_by_endpoint.csv "${testcase_count_by_endpoint_q}")

  fi

  # output csv row for these test results
  if ${output_csv}; then
    printf "%-45s, %5d, %10s, %-20s, %5d" ${job} ${run_num} ${run_at} ${version_without_sha} ${num_tests}
    echo    ", ${cov_tot_pct_all}, ${cov_tot_pct_stable}, ${cov_tot_pct_stablecore}"
  fi
done
